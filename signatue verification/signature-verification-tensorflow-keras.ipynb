{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:54:01.327870Z",
     "iopub.status.busy": "2021-05-26T15:54:01.327524Z",
     "iopub.status.idle": "2021-05-26T15:54:01.336281Z",
     "shell.execute_reply": "2021-05-26T15:54:01.334954Z",
     "shell.execute_reply.started": "2021-05-26T15:54:01.327840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Downloading tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "     -------------------------------------- 272.8/272.8 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.12.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 2.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.2-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 4.1/4.1 MB 810.0 kB/s eta 0:00:00\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Downloading numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "     ---------------------------------------- 14.7/14.7 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-4.23.3-cp39-cp39-win_amd64.whl (422 kB)\n",
      "     -------------------------------------- 422.5/422.5 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "     ---------------------------------------- 24.4/24.4 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.3.0)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "     -------------------------------------- 440.7/440.7 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.5/126.5 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 5.6/5.6 MB 3.0 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (63.4.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.9.1)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Downloading ml_dtypes-0.2.0-cp39-cp39-win_amd64.whl (938 kB)\n",
      "     -------------------------------------- 938.4/938.4 kB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.20.0-py2.py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.5/181.5 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.12-py3-none-any.whl size=1498562 sha256=57059410d76f7495f713d532d2bf88f1c34263921e096c33b4d4d5cf9d5a2f55\n",
      "  Stored in directory: c:\\users\\hanife\\appdata\\local\\pip\\cache\\wheels\\ca\\6c\\0b\\dab434867ee492673dd15dbf9f6cce85781b555432a92bfb10\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, oauthlib, numpy, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, opt-einsum, ml-dtypes, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.20.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.54.2 jax-0.4.12 libclang-16.0.0 ml-dtypes-0.2.0 numpy-1.23.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.3 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.12.3 tensorboard-data-server-0.7.1 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-intel-2.12.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\hanife\\anaconda3\\lib\\site-packages (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hanife\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hanife\\anaconda3\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: keras in c:\\users\\hanife\\anaconda3\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install matplotlib\n",
    "!pip install numpy\n",
    "!pip install keras\n",
    "!pip install PIL\n",
    "from PIL import Image \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Train already exists.\n",
      "A subdirectory or file Test already exists.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n",
      "The syntax of the command is incorrect.\n"
     ]
    }
   ],
   "source": [
    "!mkdir Train\n",
    "!mkdir Test\n",
    "\n",
    "!mkdir Train/Fake\n",
    "!mkdir Train/Real\n",
    "\n",
    "!mkdir Test/Fake\n",
    "!mkdir Test/Real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:06.156468Z",
     "iopub.status.busy": "2021-05-26T15:30:06.156018Z",
     "iopub.status.idle": "2021-05-26T15:30:10.777816Z",
     "shell.execute_reply": "2021-05-26T15:30:10.776372Z",
     "shell.execute_reply.started": "2021-05-26T15:30:06.156402Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"Train/Fake\", exist_ok=True)\n",
    "os.makedirs(\"Train/Real\", exist_ok=True)\n",
    "os.makedirs(\"Test/Fake\", exist_ok=True)\n",
    "os.makedirs(\"Test/Real\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:10.783628Z",
     "iopub.status.busy": "2021-05-26T15:30:10.783282Z",
     "iopub.status.idle": "2021-05-26T15:30:22.135944Z",
     "shell.execute_reply": "2021-05-26T15:30:22.134610Z",
     "shell.execute_reply.started": "2021-05-26T15:30:10.783594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train verilerini keras 'ın okuyabileceği şekilde konumlarını yeniden düzenliyorum.\n",
    "\n",
    "PATH = \"C:\\\\Users\\\\Hanife\\\\Desktop\\\\gg\\\\dataset\\\\train\"\n",
    "\n",
    "for i in os.listdir(PATH):\n",
    "    control = i.split(\"_\")\n",
    "    \n",
    "    try:\n",
    "        if control[1] == \"forg\":\n",
    "            os.system(\"cp -r {} Train\\\\Fake\".format(PATH + \"\\\\\" + i))\n",
    "    except:\n",
    "        os.system(\"cp -r {} Train\\\\Real\".format(PATH + \"\\\\\" + i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:22.138935Z",
     "iopub.status.busy": "2021-05-26T15:30:22.138490Z",
     "iopub.status.idle": "2021-05-26T15:30:25.427894Z",
     "shell.execute_reply": "2021-05-26T15:30:25.426624Z",
     "shell.execute_reply.started": "2021-05-26T15:30:22.138884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test verilerini keras 'ın okuyabileceği şekilde konumlarını yeniden düzenliyorum.\n",
    "\n",
    "PATH = \"C:\\\\Users\\\\Hanife\\\\Desktop\\\\gg\\\\dataset\\\\test\"\n",
    "\n",
    "for i in os.listdir(PATH):\n",
    "    \n",
    "    contol = i.split(\"_\")\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        if contol[1]==\"forg\":\n",
    "            \n",
    "            os.system(\"cp -r {} Test/Fake\".format(PATH+i))\n",
    "            \n",
    "    except:\n",
    "        \n",
    "        os.system(\"cp -r {} Test/Real\".format(PATH+i))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:25.430601Z",
     "iopub.status.busy": "2021-05-26T15:30:25.430034Z",
     "iopub.status.idle": "2021-05-26T15:30:25.436304Z",
     "shell.execute_reply": "2021-05-26T15:30:25.435038Z",
     "shell.execute_reply.started": "2021-05-26T15:30:25.430548Z"
    }
   },
   "outputs": [],
   "source": [
    "# konumları\n",
    "\n",
    "train_dir = os.path.join(\".\", \"Train\")\n",
    "test_dir = os.path.join(\".\", \"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:25.439290Z",
     "iopub.status.busy": "2021-05-26T15:30:25.438455Z",
     "iopub.status.idle": "2021-05-26T15:30:25.450692Z",
     "shell.execute_reply": "2021-05-26T15:30:25.449514Z",
     "shell.execute_reply.started": "2021-05-26T15:30:25.439244Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\n",
    "      # resim pixellerini 0,1 arasına sıkıştırma\n",
    "      rescale=1./255,\n",
    "\n",
    "      # derece cinsinden (0-180) resimlerin rastgele döndürülme açısı\n",
    "      rotation_range=40,\n",
    "\n",
    "      # resimlerin yatayda ve dikeyde kaydırılma oranları\n",
    "      width_shift_range=0.2,\n",
    "\n",
    "      # resimlerin yatayda ve dikeyde kaydırılma oranları\n",
    "      height_shift_range=0.2,\n",
    "\n",
    "      # burkma işlemi\n",
    "      shear_range=0.2,\n",
    "\n",
    "      # yakınlaştırma işlemi\n",
    "      zoom_range=0.2,\n",
    "\n",
    "      # dikeyde resim döndürme\n",
    "      horizontal_flip=True,\n",
    "\n",
    "      # işlemlerden sonra ortaya çıkan  fazla \n",
    "      # görüntü noktalarının nasıl doldurulacağını belirler\n",
    "      fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:25.454685Z",
     "iopub.status.busy": "2021-05-26T15:30:25.454281Z",
     "iopub.status.idle": "2021-05-26T15:30:25.572047Z",
     "shell.execute_reply": "2021-05-26T15:30:25.570793Z",
     "shell.execute_reply.started": "2021-05-26T15:30:25.454651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "\n",
    "        # hedef dizin\n",
    "        train_dir,\n",
    "\n",
    "        # tüm resimler (150x150) olarak boyutlandırılacak\n",
    "        target_size=(200, 200),\n",
    "\n",
    "        # yığın boyutu\n",
    "        batch_size=64,\n",
    "\n",
    "        # binary_crossentropy kullandığımız için\n",
    "        # ikili etiketler gerekiyor.\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:25.576141Z",
     "iopub.status.busy": "2021-05-26T15:30:25.575463Z",
     "iopub.status.idle": "2021-05-26T15:30:25.688046Z",
     "shell.execute_reply": "2021-05-26T15:30:25.686947Z",
     "shell.execute_reply.started": "2021-05-26T15:30:25.576092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "\n",
    "        test_dir,\n",
    "\n",
    "        target_size=(200, 200),\n",
    "\n",
    "        batch_size=64,\n",
    "\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:46:04.527620Z",
     "iopub.status.busy": "2021-05-26T15:46:04.527114Z",
     "iopub.status.idle": "2021-05-26T15:46:06.112397Z",
     "shell.execute_reply": "2021-05-26T15:46:06.111213Z",
     "shell.execute_reply.started": "2021-05-26T15:46:04.527576Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_generator[0][0][5])\n",
    "print(\"Label : \",train_generator[0][1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:27.384573Z",
     "iopub.status.busy": "2021-05-26T15:30:27.383957Z",
     "iopub.status.idle": "2021-05-26T15:30:29.006755Z",
     "shell.execute_reply": "2021-05-26T15:30:29.005286Z",
     "shell.execute_reply.started": "2021-05-26T15:30:27.384526Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_generator[0][0][60])\n",
    "print(\"Label : \",train_generator[0][1][60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:29.009375Z",
     "iopub.status.busy": "2021-05-26T15:30:29.008712Z",
     "iopub.status.idle": "2021-05-26T15:30:31.547607Z",
     "shell.execute_reply": "2021-05-26T15:30:31.546489Z",
     "shell.execute_reply.started": "2021-05-26T15:30:29.009326Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    \n",
    "    self.cnn1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(3,200,200))\n",
    "    self.cnn2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\n",
    "    self.cnn3 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')\n",
    "    \n",
    "    self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    self.dense1 = tf.keras.layers.Dense(512, activation='relu')\n",
    "    self.dense2 = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    \n",
    "    x = self.cnn1(inputs)\n",
    "    x = self.cnn2(x)\n",
    "    x = self.cnn3(x)\n",
    "    x = self.flatten(x)\n",
    "    x = self.dense1(x)\n",
    "    x = self.dense2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:31.549934Z",
     "iopub.status.busy": "2021-05-26T15:30:31.549204Z",
     "iopub.status.idle": "2021-05-26T15:30:31.638898Z",
     "shell.execute_reply": "2021-05-26T15:30:31.637807Z",
     "shell.execute_reply.started": "2021-05-26T15:30:31.549848Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (None, 200, 200, 3)\n",
    "model.build(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:31.640852Z",
     "iopub.status.busy": "2021-05-26T15:30:31.640370Z",
     "iopub.status.idle": "2021-05-26T15:30:31.660455Z",
     "shell.execute_reply": "2021-05-26T15:30:31.659045Z",
     "shell.execute_reply.started": "2021-05-26T15:30:31.640820Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # kayıp fonksiyonu\n",
    "    loss=\"binary_crossentropy\",\n",
    "    \n",
    "    # eniyileme:\n",
    "    # ağımızın girdisi olan veri ile oluşturduğu kaybı göz önünde\n",
    "    # bulundurarak kendisini güncelleme mekanizması\n",
    "    optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "\n",
    "    # eğitim ve test süresince takip edilecek metrikler. \n",
    "    metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:30:31.664812Z",
     "iopub.status.busy": "2021-05-26T15:30:31.664478Z",
     "iopub.status.idle": "2021-05-26T15:45:45.490862Z",
     "shell.execute_reply": "2021-05-26T15:45:45.489556Z",
     "shell.execute_reply.started": "2021-05-26T15:30:31.664781Z"
    }
   },
   "outputs": [],
   "source": [
    "# acc, loss, val_acc, val_loss değerlerini history adlı değişkenden alacağız.\n",
    "history = model.fit_generator(\n",
    "\n",
    "    # eğitim verileri\n",
    "    train_generator,\n",
    "\n",
    "    # döngü bitene kadar geçeceği örnek sayısı (alınacak yığın)\n",
    "    steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
    "\n",
    "    # döngü sayısı\n",
    "    epochs=40,\n",
    "\n",
    "    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:46:15.233224Z",
     "iopub.status.busy": "2021-05-26T15:46:15.232815Z",
     "iopub.status.idle": "2021-05-26T15:46:15.607136Z",
     "shell.execute_reply": "2021-05-26T15:46:15.605713Z",
     "shell.execute_reply.started": "2021-05-26T15:46:15.233180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Eğitim başarım skoru\n",
    "acc = history.history[\"acc\"]\n",
    "\n",
    "# eğitim kayıp skoru\n",
    "loss = history.history[\"loss\"]\n",
    "\n",
    "# epochs sayısına göre grafik çizdireceğiz.\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# eğitim başarımını kendine özel çizdirdik.\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Eğitim başarımı\")\n",
    "\n",
    "# çizdirmemizin başlığı\n",
    "plt.title(\"Eğitim başarımı\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# eğitim kaybını kendine özel çizdirdik.\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Eğitim kaybı\")\n",
    "\n",
    "\n",
    "# çizdirmemizin başlığı\n",
    "plt.title(\"Eğitim kaybı\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# ekrana çıkartma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:48:54.785189Z",
     "iopub.status.busy": "2021-05-26T15:48:54.784843Z",
     "iopub.status.idle": "2021-05-26T15:48:57.750005Z",
     "shell.execute_reply": "2021-05-26T15:48:57.748574Z",
     "shell.execute_reply.started": "2021-05-26T15:48:54.785144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test verileri ile kayip ve doğrulama \n",
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:55:04.632744Z",
     "iopub.status.busy": "2021-05-26T15:55:04.632337Z",
     "iopub.status.idle": "2021-05-26T15:55:05.520670Z",
     "shell.execute_reply": "2021-05-26T15:55:05.519520Z",
     "shell.execute_reply.started": "2021-05-26T15:55:04.632712Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_generator[0][0][5])\n",
    "print(\"Label : \",test_generator[0][1][5])\n",
    "\n",
    "test_input = test_generator[0][0][5]\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "\n",
    "pred = model.predict(test_input)\n",
    "\n",
    "if pred>=0.5:\n",
    "    pred = 1\n",
    "    \n",
    "else:\n",
    "    \n",
    "    pred = 0\n",
    "    \n",
    "print(\"Predict : \",float(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-26T15:55:29.603144Z",
     "iopub.status.busy": "2021-05-26T15:55:29.602799Z",
     "iopub.status.idle": "2021-05-26T15:55:30.507378Z",
     "shell.execute_reply": "2021-05-26T15:55:30.506311Z",
     "shell.execute_reply.started": "2021-05-26T15:55:29.603113Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_generator[0][0][30])\n",
    "print(\"Label : \",test_generator[0][1][30])\n",
    "\n",
    "test_input = test_generator[0][0][30]\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "test_input = np.expand_dims(test_input,axis=0)\n",
    "\n",
    "pred = model.predict(test_input)\n",
    "\n",
    "if pred>=0.5:\n",
    "    pred = 1\n",
    "    \n",
    "else:\n",
    "    \n",
    "    pred = 0\n",
    "    \n",
    "print(\"Predict : \",float(pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
